diff --git a/tensorflow/core/kernels/conv_grad_filter_ops.cc b/tensorflow/core/kernels/conv_grad_filter_ops.cc
index b16d3c7..0518c6e 100644
--- a/tensorflow/core/kernels/conv_grad_filter_ops.cc
+++ b/tensorflow/core/kernels/conv_grad_filter_ops.cc
@@ -838,11 +838,16 @@ void LaunchConv2DBackpropFilterOp<Eigen::GpuDevice, T>::operator()(
   VLOG(3) << "Compute Conv2DBackpropFilter with cuDNN:"
           << " data_format=" << ToString(data_format)
           << " compute_data_format=" << ToString(compute_data_format);
-
+  // Tom: return type as constexpr will raise an compilation error on macOS such as 
+  /**
+   tensorflow/core/kernels/conv_grad_filter_ops.cc:736:18: error: constexpr variable 'kComputeInNHWC' must be initialized by a constant expression
   constexpr auto kComputeInNHWC =
+   */
+  // Therefore, I removed the keyword constexpr. This change is also applied to conv_grad_input_ops.cc, and conv_ops.cc.
+  auto kComputeInNHWC =
       std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,
                       se::dnn::FilterLayout::kOutputYXInput);
-  constexpr auto kComputeInNCHW =
+  auto kComputeInNCHW =
       std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,
                       se::dnn::FilterLayout::kOutputInputYX);
 
diff --git a/tensorflow/core/kernels/conv_grad_input_ops.cc b/tensorflow/core/kernels/conv_grad_input_ops.cc
index fd2f569..4077a70 100644
--- a/tensorflow/core/kernels/conv_grad_input_ops.cc
+++ b/tensorflow/core/kernels/conv_grad_input_ops.cc
@@ -992,11 +992,11 @@ void LaunchConv2DBackpropInputOp<GPUDevice, T>::operator()(
   VLOG(3) << "Compute Conv2DBackpropInput with cuDNN:"
           << " data_format=" << ToString(data_format)
           << " compute_data_format=" << ToString(compute_data_format);
-
-  constexpr auto kComputeInNHWC =
+  // Tom: remove constexpr to be compatiable with macOS.
+  auto kComputeInNHWC =
       std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,
                       se::dnn::FilterLayout::kOutputYXInput);
-  constexpr auto kComputeInNCHW =
+  auto kComputeInNCHW =
       std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,
                       se::dnn::FilterLayout::kOutputInputYX);
 
diff --git a/tensorflow/core/kernels/conv_ops.cc b/tensorflow/core/kernels/conv_ops.cc
index ab8e24a..f549edc 100644
--- a/tensorflow/core/kernels/conv_ops.cc
+++ b/tensorflow/core/kernels/conv_ops.cc
@@ -863,11 +863,11 @@ void LaunchConv2DOp<GPUDevice, T>::operator()(
   CHECK(common_padding_rows >= 0 && common_padding_cols >= 0)  // Crash OK
       << "Negative row or col paddings: (" << common_padding_rows << ", "
       << common_padding_cols << ")";
-
-  constexpr auto kComputeInNHWC =
+  // Tom: remove constexpr to be compatiable with macOS.
+  auto kComputeInNHWC =
       std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,
                       se::dnn::FilterLayout::kOutputYXInput);
-  constexpr auto kComputeInNCHW =
+  auto kComputeInNCHW =
       std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,
                       se::dnn::FilterLayout::kOutputInputYX);
 
diff --git a/tensorflow/core/kernels/data/experimental/snapshot_util.cc b/tensorflow/core/kernels/data/experimental/snapshot_util.cc
index 3ad1345..3eff79a 100644
--- a/tensorflow/core/kernels/data/experimental/snapshot_util.cc
+++ b/tensorflow/core/kernels/data/experimental/snapshot_util.cc
@@ -40,9 +40,14 @@ limitations under the License.
 namespace tensorflow {
 namespace data {
 namespace snapshot_util {
-
-/* static */ constexpr const int64 Reader::kSnappyReaderInputBufferSizeBytes;
-/* static */ constexpr const int64 Reader::kSnappyReaderOutputBufferSizeBytes;
+// Tom: Intializing kSnappyReaderInputBufferSizeBytes and kSnappyReaderOutputBufferSizeBytes in class definition and 
+// refer to them in cc file causes symbol not found error on macOS. 
+// The change solves #39262.
+  static constexpr const int64 kSnappyReaderInputBufferSizeBytes =
+  //    1 << 30;  // 1 GiB
+  // TODO(b/148804377): Set this in a smarter fashion.
+  static constexpr const int64 kSnappyReaderOutputBufferSizeBytes =
+  //    32 << 20;  // 32 MiB
 
 Writer::Writer(const std::string& filename, const std::string& compression_type,
                int version, const DataTypeVector& dtypes)
diff --git a/tensorflow/core/kernels/data/experimental/snapshot_util.h b/tensorflow/core/kernels/data/experimental/snapshot_util.h
index dd15c59..dcf64d6 100644
--- a/tensorflow/core/kernels/data/experimental/snapshot_util.h
+++ b/tensorflow/core/kernels/data/experimental/snapshot_util.h
@@ -103,11 +103,11 @@ class Reader {
   // The reader input buffer size is deliberately large because the input reader
   // will throw an error if the compressed block length cannot fit in the input
   // buffer.
-  static constexpr const int64 kSnappyReaderInputBufferSizeBytes =
-      1 << 30;  // 1 GiB
+  //static constexpr const int64 kSnappyReaderInputBufferSizeBytes =
+  //    1 << 30;  // 1 GiB
   // TODO(b/148804377): Set this in a smarter fashion.
-  static constexpr const int64 kSnappyReaderOutputBufferSizeBytes =
-      32 << 20;  // 32 MiB
+  //static constexpr const int64 kSnappyReaderOutputBufferSizeBytes =
+  //    32 << 20;  // 32 MiB
   static constexpr const size_t kHeaderSize = sizeof(uint64);
 
   static constexpr const char* const kClassName = "SnapshotReader";
diff --git a/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc b/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc
index 089fa8c..5a439e1 100644
--- a/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc
+++ b/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc
@@ -38,9 +38,13 @@ static const char kNotInvertibleMsg[] = "The matrix is not invertible.";
 
 static const char kNotInvertibleScalarMsg[] =
     "The matrix is not invertible: it is a scalar with value zero.";
-
+// Tom: The following should be a device function. The original declaration will raise a compilation error on macOS such as 
+/**
+tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc(46): error: calling a __host__ function("std::__1::operator ==<float> ") from a __global__ function("tensorflow::SolveForSizeOneOrTwoKernel< ::std::__1::complex<float> > ") is not allowed
+tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc(55): error: calling a __host__ function("std::__1::operator ==<float> ") from a __global__ function("tensorflow::SolveForSizeOneOrTwoKernel< ::std::__1::complex<float> > ") is not allowed
+ * */
 template <typename Scalar>
-__global__ void SolveForSizeOneOrTwoKernel(const int m,
+__device__ void SolveForSizeOneOrTwoKernel(const int m,
                                            const Scalar* __restrict__ diags,
                                            const Scalar* __restrict__ rhs,
                                            const int num_rhs,
diff --git a/tensorflow/core/platform/tstring.h b/tensorflow/core/platform/tstring.h
index 3fe1be2..2f0f51c 100644
--- a/tensorflow/core/platform/tstring.h
+++ b/tensorflow/core/platform/tstring.h
@@ -225,7 +225,21 @@ class tstring {
   friend bool operator==(const std::string& a, const tstring& b);
   friend tstring operator+(const tstring& a, const tstring& b);
   friend std::ostream& operator<<(std::ostream& o, const tstring& str);
-  friend std::hash<tstring>;
+  //friend std::hash<tstring>;
+  // Tom: The above hash declaration causes the following compilation error on macOS
+  /**
+   ./tensorflow/core/platform/tstring.h:228:15: error: no template named 'hash'; did you mean 'std::hash'?
+friend struct hash< tstring> ; 
+              ^~~~
+              std::hash
+/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/type_traits:400:29: note: 'std::hash' declared here
+template< class _Tp> struct hash; 
+                            ^
+1 error generated.
+ERROR: /Volumes/Data/libraries/tensorflow/tensorflow/core/kernels/BUILD:384:1: output 'tensorflow/core/kernels/_objs/fill_functor_gpu/fill_functor.cu.pic.o' was not created
+   */
+  // I tried adding 'struct' keyword before std::hash, and adding '#include <functional>' without luck. The only workaround availabe now is to remove the 
+  // declaration. However, I do not know if the change breaks anything.
 };
 
 // Non-member function overloads
diff --git a/tensorflow/core/util/gpu_device_functions.h b/tensorflow/core/util/gpu_device_functions.h
index b4de2ff..26d7587 100644
--- a/tensorflow/core/util/gpu_device_functions.h
+++ b/tensorflow/core/util/gpu_device_functions.h
@@ -192,11 +192,14 @@ __device__ const unsigned kGpuWarpAll = 0xffffffff;
 __device__ inline unsigned GpuLaneId() {
   unsigned int lane_id;
 #if GOOGLE_CUDA
-#if __clang__
-  return __nvvm_read_ptx_sreg_laneid();
-#else   // __clang__
+//#if __clang__
+//  return __nvvm_read_ptx_sreg_laneid(); // Tom: The function is not available on macOS and will cause a compilation error such as
+/**
+ ./tensorflow/core/util/gpu_device_functions.h(144): error: identifier "__nvvm_read_ptx_sreg_laneid" is undefined
+ */
+//#else   // __clang__
   asm("mov.u32 %0, %%laneid;" : "=r"(lane_id));
-#endif  // __clang__
+//#endif  // __clang__
 #elif TENSORFLOW_USE_ROCM
   lane_id = __lane_id();
 #endif
diff --git a/third_party/gpus/cuda_configure.bzl b/third_party/gpus/cuda_configure.bzl
index 545aeeb..e843e72 100644
--- a/third_party/gpus/cuda_configure.bzl
+++ b/third_party/gpus/cuda_configure.bzl
@@ -462,7 +462,36 @@ def _check_cuda_lib_params(lib, cpu_value, basedir, version, static = False):
         _lib_path(lib, cpu_value, basedir, version, static),
         _should_check_soname(version, static),
     )
+# Tom: The implementation does not work at macOS since command objdump return different information from linux.
+# The implementation uses a script.py to detect CUDA libraries. But I think the previous version (v2.1.0 or before) is
+# better to generalize to both Linux and macOS. I provide a separate and working version on macOS here.
+def _check_cuda_libs_macOS(repository_ctx, script_path, paths, check_soname = True):
+    """
+      Finds a library among a list of potential paths.
+      Args:
+        paths: List of paths to inspect.
+      Returns:
+        Returns the first path in paths that exist.
+    """
+    objdump = repository_ctx.which("objdump")
+    mismatches = []
+    for path in paths:
+        path = path[0]
+         #print('mypath', path)
+        #if not path.exists:
+        # continue
+        output = repository_ctx.execute([objdump, "-p", str(path)]).stdout
+        output = [line for line in output.splitlines() if "name @rpath/" in line]
+        sonames = [line.strip().split("/")[-1] for line in output]
+        sonames = [sonames[0].strip().split(" ")[0] for line in output]
+        return path
+    if mismatches:
+        auto_configure_fail(
+            "None of the libraries match their SONAME: " + ", ".join(mismatches),
+        )
+    auto_configure_fail("No library found under: " + ", ".join(paths))
 
+# The following original version deos not work on macOS. 
 def _check_cuda_libs(repository_ctx, script_path, libs):
     python_bin = get_python_bin(repository_ctx)
     contents = repository_ctx.read(script_path).splitlines()
@@ -499,7 +528,9 @@ def _find_libs(repository_ctx, check_cuda_libs_script, cuda_config):
         Map of library names to structs of filename and path.
       """
     cpu_value = cuda_config.cpu_value
+    is_macos = cpu_value == "Darwin" # Tom: add for macOS
     stub_dir = "" if is_windows(repository_ctx) else "/stubs"
+    stub_dir = "" if is_macos else "/stubs" # Tom: add for macOS. /stubs is not available on macOS.
 
     check_cuda_libs_params = {
         "cuda": _check_cuda_lib_params(
@@ -575,7 +606,10 @@ def _find_libs(repository_ctx, check_cuda_libs_script, cuda_config):
     }
 
     # Verify that the libs actually exist at their locations.
-    _check_cuda_libs(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())
+    if is_macos:
+        _check_cuda_libs_macOS(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())
+    else:
+        _check_cuda_libs(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())
 
     paths = {filename: v[0] for (filename, v) in check_cuda_libs_params.items()}
     return paths
@@ -639,6 +673,7 @@ def _get_cuda_config(repository_ctx, find_cuda_config_script):
     toolkit_path = config["cuda_toolkit_path"]
 
     is_windows = cpu_value == "Windows"
+    is_macos = cpu_value == "Darwin" # Tom: add for macOS
     cuda_version = config["cuda_version"].split(".")
     cuda_major = cuda_version[0]
     cuda_minor = cuda_version[1]
@@ -818,12 +853,13 @@ def make_copy_dir_rule(repository_ctx, name, src_dir, out_dir):
     # '@D' already contains the relative path for a single file, see
     # http://docs.bazel.build/versions/master/be/make-variables.html#predefined_genrule_variables
     out_dir = "$(@D)/%s" % out_dir if len(outs) > 1 else "$(@D)"
+    # Tom: parameter '-rLf' is not valid on macOS. Therefore, I replace it with '-r -f'.
     return """genrule(
     name = "%s",
     outs = [
 %s
     ],
-    cmd = \"""cp -rLf "%s/." "%s/" \""",
+    cmd = \"""cp -r -f "%s/." "%s/" \""", 
 )""" % (name, "\n".join(outs), src_dir, out_dir)
 
 def _flag_enabled(repository_ctx, flag_name):
diff --git a/v2.2_macos.patch b/v2.2_macos.patch
new file mode 100644
index 0000000..384c4b7
--- /dev/null
+++ b/v2.2_macos.patch
@@ -0,0 +1,260 @@
+diff --git a/tensorflow/core/kernels/conv_grad_filter_ops.cc b/tensorflow/core/kernels/conv_grad_filter_ops.cc
+index b16d3c7..0518c6e 100644
+--- a/tensorflow/core/kernels/conv_grad_filter_ops.cc
++++ b/tensorflow/core/kernels/conv_grad_filter_ops.cc
+@@ -838,11 +838,16 @@ void LaunchConv2DBackpropFilterOp<Eigen::GpuDevice, T>::operator()(
+   VLOG(3) << "Compute Conv2DBackpropFilter with cuDNN:"
+           << " data_format=" << ToString(data_format)
+           << " compute_data_format=" << ToString(compute_data_format);
+-
++  // Tom: return type as constexpr will raise an compilation error on macOS such as 
++  /**
++   tensorflow/core/kernels/conv_grad_filter_ops.cc:736:18: error: constexpr variable 'kComputeInNHWC' must be initialized by a constant expression
+   constexpr auto kComputeInNHWC =
++   */
++  // Therefore, I removed the keyword constexpr. This change is also applied to conv_grad_input_ops.cc, and conv_ops.cc.
++  auto kComputeInNHWC =
+       std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,
+                       se::dnn::FilterLayout::kOutputYXInput);
+-  constexpr auto kComputeInNCHW =
++  auto kComputeInNCHW =
+       std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,
+                       se::dnn::FilterLayout::kOutputInputYX);
+ 
+diff --git a/tensorflow/core/kernels/conv_grad_input_ops.cc b/tensorflow/core/kernels/conv_grad_input_ops.cc
+index fd2f569..4077a70 100644
+--- a/tensorflow/core/kernels/conv_grad_input_ops.cc
++++ b/tensorflow/core/kernels/conv_grad_input_ops.cc
+@@ -992,11 +992,11 @@ void LaunchConv2DBackpropInputOp<GPUDevice, T>::operator()(
+   VLOG(3) << "Compute Conv2DBackpropInput with cuDNN:"
+           << " data_format=" << ToString(data_format)
+           << " compute_data_format=" << ToString(compute_data_format);
+-
+-  constexpr auto kComputeInNHWC =
++  // Tom: remove constexpr to be compatiable with macOS.
++  auto kComputeInNHWC =
+       std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,
+                       se::dnn::FilterLayout::kOutputYXInput);
+-  constexpr auto kComputeInNCHW =
++  auto kComputeInNCHW =
+       std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,
+                       se::dnn::FilterLayout::kOutputInputYX);
+ 
+diff --git a/tensorflow/core/kernels/conv_ops.cc b/tensorflow/core/kernels/conv_ops.cc
+index ab8e24a..f549edc 100644
+--- a/tensorflow/core/kernels/conv_ops.cc
++++ b/tensorflow/core/kernels/conv_ops.cc
+@@ -863,11 +863,11 @@ void LaunchConv2DOp<GPUDevice, T>::operator()(
+   CHECK(common_padding_rows >= 0 && common_padding_cols >= 0)  // Crash OK
+       << "Negative row or col paddings: (" << common_padding_rows << ", "
+       << common_padding_cols << ")";
+-
+-  constexpr auto kComputeInNHWC =
++  // Tom: remove constexpr to be compatiable with macOS.
++  auto kComputeInNHWC =
+       std::make_tuple(se::dnn::DataLayout::kBatchYXDepth,
+                       se::dnn::FilterLayout::kOutputYXInput);
+-  constexpr auto kComputeInNCHW =
++  auto kComputeInNCHW =
+       std::make_tuple(se::dnn::DataLayout::kBatchDepthYX,
+                       se::dnn::FilterLayout::kOutputInputYX);
+ 
+diff --git a/tensorflow/core/kernels/data/experimental/snapshot_util.cc b/tensorflow/core/kernels/data/experimental/snapshot_util.cc
+index 3ad1345..3eff79a 100644
+--- a/tensorflow/core/kernels/data/experimental/snapshot_util.cc
++++ b/tensorflow/core/kernels/data/experimental/snapshot_util.cc
+@@ -40,9 +40,14 @@ limitations under the License.
+ namespace tensorflow {
+ namespace data {
+ namespace snapshot_util {
+-
+-/* static */ constexpr const int64 Reader::kSnappyReaderInputBufferSizeBytes;
+-/* static */ constexpr const int64 Reader::kSnappyReaderOutputBufferSizeBytes;
++// Tom: Intializing kSnappyReaderInputBufferSizeBytes and kSnappyReaderOutputBufferSizeBytes in class definition and 
++// refer to them in cc file causes symbol not found error on macOS. 
++// The change solves #39262.
++  static constexpr const int64 kSnappyReaderInputBufferSizeBytes =
++  //    1 << 30;  // 1 GiB
++  // TODO(b/148804377): Set this in a smarter fashion.
++  static constexpr const int64 kSnappyReaderOutputBufferSizeBytes =
++  //    32 << 20;  // 32 MiB
+ 
+ Writer::Writer(const std::string& filename, const std::string& compression_type,
+                int version, const DataTypeVector& dtypes)
+diff --git a/tensorflow/core/kernels/data/experimental/snapshot_util.h b/tensorflow/core/kernels/data/experimental/snapshot_util.h
+index dd15c59..dcf64d6 100644
+--- a/tensorflow/core/kernels/data/experimental/snapshot_util.h
++++ b/tensorflow/core/kernels/data/experimental/snapshot_util.h
+@@ -103,11 +103,11 @@ class Reader {
+   // The reader input buffer size is deliberately large because the input reader
+   // will throw an error if the compressed block length cannot fit in the input
+   // buffer.
+-  static constexpr const int64 kSnappyReaderInputBufferSizeBytes =
+-      1 << 30;  // 1 GiB
++  //static constexpr const int64 kSnappyReaderInputBufferSizeBytes =
++  //    1 << 30;  // 1 GiB
+   // TODO(b/148804377): Set this in a smarter fashion.
+-  static constexpr const int64 kSnappyReaderOutputBufferSizeBytes =
+-      32 << 20;  // 32 MiB
++  //static constexpr const int64 kSnappyReaderOutputBufferSizeBytes =
++  //    32 << 20;  // 32 MiB
+   static constexpr const size_t kHeaderSize = sizeof(uint64);
+ 
+   static constexpr const char* const kClassName = "SnapshotReader";
+diff --git a/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc b/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc
+index 089fa8c..5a439e1 100644
+--- a/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc
++++ b/tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc
+@@ -38,9 +38,13 @@ static const char kNotInvertibleMsg[] = "The matrix is not invertible.";
+ 
+ static const char kNotInvertibleScalarMsg[] =
+     "The matrix is not invertible: it is a scalar with value zero.";
+-
++// Tom: The following should be a device function. The original declaration will raise a compilation error on macOS such as 
++/**
++tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc(46): error: calling a __host__ function("std::__1::operator ==<float> ") from a __global__ function("tensorflow::SolveForSizeOneOrTwoKernel< ::std::__1::complex<float> > ") is not allowed
++tensorflow/core/kernels/tridiagonal_solve_op_gpu.cu.cc(55): error: calling a __host__ function("std::__1::operator ==<float> ") from a __global__ function("tensorflow::SolveForSizeOneOrTwoKernel< ::std::__1::complex<float> > ") is not allowed
++ * */
+ template <typename Scalar>
+-__global__ void SolveForSizeOneOrTwoKernel(const int m,
++__device__ void SolveForSizeOneOrTwoKernel(const int m,
+                                            const Scalar* __restrict__ diags,
+                                            const Scalar* __restrict__ rhs,
+                                            const int num_rhs,
+diff --git a/tensorflow/core/platform/tstring.h b/tensorflow/core/platform/tstring.h
+index 3fe1be2..2f0f51c 100644
+--- a/tensorflow/core/platform/tstring.h
++++ b/tensorflow/core/platform/tstring.h
+@@ -225,7 +225,21 @@ class tstring {
+   friend bool operator==(const std::string& a, const tstring& b);
+   friend tstring operator+(const tstring& a, const tstring& b);
+   friend std::ostream& operator<<(std::ostream& o, const tstring& str);
+-  friend std::hash<tstring>;
++  //friend std::hash<tstring>;
++  // Tom: The above hash declaration causes the following compilation error on macOS
++  /**
++   ./tensorflow/core/platform/tstring.h:228:15: error: no template named 'hash'; did you mean 'std::hash'?
++friend struct hash< tstring> ; 
++              ^~~~
++              std::hash
++/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/type_traits:400:29: note: 'std::hash' declared here
++template< class _Tp> struct hash; 
++                            ^
++1 error generated.
++ERROR: /Volumes/Data/libraries/tensorflow/tensorflow/core/kernels/BUILD:384:1: output 'tensorflow/core/kernels/_objs/fill_functor_gpu/fill_functor.cu.pic.o' was not created
++   */
++  // I tried adding 'struct' keyword before std::hash, and adding '#include <functional>' without luck. The only workaround availabe now is to remove the 
++  // declaration. However, I do not know if the change breaks anything.
+ };
+ 
+ // Non-member function overloads
+diff --git a/tensorflow/core/util/gpu_device_functions.h b/tensorflow/core/util/gpu_device_functions.h
+index b4de2ff..26d7587 100644
+--- a/tensorflow/core/util/gpu_device_functions.h
++++ b/tensorflow/core/util/gpu_device_functions.h
+@@ -192,11 +192,14 @@ __device__ const unsigned kGpuWarpAll = 0xffffffff;
+ __device__ inline unsigned GpuLaneId() {
+   unsigned int lane_id;
+ #if GOOGLE_CUDA
+-#if __clang__
+-  return __nvvm_read_ptx_sreg_laneid();
+-#else   // __clang__
++//#if __clang__
++//  return __nvvm_read_ptx_sreg_laneid(); // Tom: The function is not available on macOS and will cause a compilation error such as
++/**
++ ./tensorflow/core/util/gpu_device_functions.h(144): error: identifier "__nvvm_read_ptx_sreg_laneid" is undefined
++ */
++//#else   // __clang__
+   asm("mov.u32 %0, %%laneid;" : "=r"(lane_id));
+-#endif  // __clang__
++//#endif  // __clang__
+ #elif TENSORFLOW_USE_ROCM
+   lane_id = __lane_id();
+ #endif
+diff --git a/third_party/gpus/cuda_configure.bzl b/third_party/gpus/cuda_configure.bzl
+index 545aeeb..9e8f0f6 100644
+--- a/third_party/gpus/cuda_configure.bzl
++++ b/third_party/gpus/cuda_configure.bzl
+@@ -462,7 +462,37 @@ def _check_cuda_lib_params(lib, cpu_value, basedir, version, static = False):
+         _lib_path(lib, cpu_value, basedir, version, static),
+         _should_check_soname(version, static),
+     )
++# Tom: The implementation does not work at macOS since command objdump return different information from linux.
++# The implementation uses a script.py to detect CUDA libraries. But I think the previous version (v2.1.0 or before) is
++# better to generalize to both Linux and macOS. I provide a working version on macOS but it needs to be modified to adapt
++# to Linux.
++def _check_cuda_libs_macOS(repository_ctx, script_path, paths, check_soname = True):
++    """
++      Finds a library among a list of potential paths.
++      Args:
++        paths: List of paths to inspect.
++      Returns:
++        Returns the first path in paths that exist.
++    """
++    objdump = repository_ctx.which("objdump")
++    mismatches = []
++    for path in paths:
++        path = path[0]
++         #print('mypath', path)
++        #if not path.exists:
++        # continue
++        output = repository_ctx.execute([objdump, "-p", str(path)]).stdout
++        output = [line for line in output.splitlines() if "name @rpath/" in line]
++        sonames = [line.strip().split("/")[-1] for line in output]
++        sonames = [sonames[0].strip().split(" ")[0] for line in output]
++        return path
++    if mismatches:
++        auto_configure_fail(
++            "None of the libraries match their SONAME: " + ", ".join(mismatches),
++        )
++    auto_configure_fail("No library found under: " + ", ".join(paths))
+ 
++# The following original version deos not work on macOS. 
+ def _check_cuda_libs(repository_ctx, script_path, libs):
+     python_bin = get_python_bin(repository_ctx)
+     contents = repository_ctx.read(script_path).splitlines()
+@@ -499,7 +529,9 @@ def _find_libs(repository_ctx, check_cuda_libs_script, cuda_config):
+         Map of library names to structs of filename and path.
+       """
+     cpu_value = cuda_config.cpu_value
++    is_macos = cpu_value == "Darwin" # Tom: add for macOS
+     stub_dir = "" if is_windows(repository_ctx) else "/stubs"
++    stub_dir = "" if is_macos else "/stubs" # Tom: add for macOS. /stubs is not available on macOS.
+ 
+     check_cuda_libs_params = {
+         "cuda": _check_cuda_lib_params(
+@@ -575,7 +607,10 @@ def _find_libs(repository_ctx, check_cuda_libs_script, cuda_config):
+     }
+ 
+     # Verify that the libs actually exist at their locations.
+-    _check_cuda_libs(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())
++    if is_macos:
++        _check_cuda_libs_macOS(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())
++    else:
++        _check_cuda_libs(repository_ctx, check_cuda_libs_script, check_cuda_libs_params.values())
+ 
+     paths = {filename: v[0] for (filename, v) in check_cuda_libs_params.items()}
+     return paths
+@@ -639,6 +674,7 @@ def _get_cuda_config(repository_ctx, find_cuda_config_script):
+     toolkit_path = config["cuda_toolkit_path"]
+ 
+     is_windows = cpu_value == "Windows"
++    is_macos = cpu_value == "Darwin" # Tom: add for macOS
+     cuda_version = config["cuda_version"].split(".")
+     cuda_major = cuda_version[0]
+     cuda_minor = cuda_version[1]
+@@ -818,12 +854,13 @@ def make_copy_dir_rule(repository_ctx, name, src_dir, out_dir):
+     # '@D' already contains the relative path for a single file, see
+     # http://docs.bazel.build/versions/master/be/make-variables.html#predefined_genrule_variables
+     out_dir = "$(@D)/%s" % out_dir if len(outs) > 1 else "$(@D)"
++    # Tom: parameter '-rLf' is not valid on macOS. Therefore, I replace it with '-r -f'.
+     return """genrule(
+     name = "%s",
+     outs = [
+ %s
+     ],
+-    cmd = \"""cp -rLf "%s/." "%s/" \""",
++    cmd = \"""cp -r -f "%s/." "%s/" \""", 
+ )""" % (name, "\n".join(outs), src_dir, out_dir)
+ 
+ def _flag_enabled(repository_ctx, flag_name):
